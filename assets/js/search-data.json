{
  
    
        "post0": {
            "title": "Ubuntu Cheat Sheet",
            "content": "Ubuntu Cheat Sheet .",
            "url": "https://andrewryanx.github.io/site/ubuntu/linux/2021/01/29/ubuntu-cheatsheet.html",
            "relUrl": "/ubuntu/linux/2021/01/29/ubuntu-cheatsheet.html",
            "date": " ‚Ä¢ Jan 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Markdown Cheat Sheet",
            "content": "Markdown Cheat Sheet . Mastering Markdown .",
            "url": "https://andrewryanx.github.io/site/markdown/2021/01/29/markdown-cheatsheet.html",
            "relUrl": "/markdown/2021/01/29/markdown-cheatsheet.html",
            "date": " ‚Ä¢ Jan 29, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Machine Learning Cheat Sheet",
            "content": "Machine Learning Cheat Sheet .",
            "url": "https://andrewryanx.github.io/site/machine%20learning/python/2021/01/29/ml-cheatsheet.html",
            "relUrl": "/machine%20learning/python/2021/01/29/ml-cheatsheet.html",
            "date": " ‚Ä¢ Jan 29, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Statistics Cheat Sheet",
            "content": "Statistics Cheat Sheet .",
            "url": "https://andrewryanx.github.io/site/statistics/python/2021/01/29/stats-cheatsheet.html",
            "relUrl": "/statistics/python/2021/01/29/stats-cheatsheet.html",
            "date": " ‚Ä¢ Jan 29, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Python Cheat Sheet",
            "content": "Python Cheat Sheet . Import Modules . import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import glob . Data Frame I/O . Read CSV . pd.read_csv(&#39;filepath filename.csv&#39;) . Create DataFrame from multiple files and assign filename to column . files = sorted(glob(&#39;filepath *.csv&#39;)); pd.concat((pd.read_csv(file).assign(filename=file) for file in files),ignore_index=True) . Write CSV . pd.to_csv(&#39;filepath filename.csv&#39;,¬†columns=[&#39;columns to write&#39;],¬†index=False) #write csv . Data Manipulation &amp; Interrogation . Select first n number of rows . df.head(n) . Select bottom n number of rows . df.tail(n) . Select random n number of rows . df.sample(n) . Get the shape of the DataFrame . df.shape . Get the dtypes of the columns . df.dtypes . Get the number of rows in dataframe . len(df) . Calculate the number of missing values . df.isna().sum().sum() . Returns series denoting duplicate rows . df.duplicated . Drop duplicates by column . df.drop_duplicates(subset=[&#39;column to check for dupes&#39;],¬†inplace=True) . Drop columns in DataFrame . df.drop(columns=[&#39;column to drop&#39;],¬†inplace=True) . Drop null values . df.dropna(axis=0,¬†how=&#39;any&#39;,¬†subset=[&#39;columns to drop if null values exist&#39;]) . Get the number of distinct values in a column . df[&#39;column&#39;].nunique() . Count numer of rows with each unique value of variable . df[&#39;column&#39;].value_counts() . Replace values in column with new value . df[&#39;column&#39;].replace(&lt;current value&gt;,&lt;target value&gt;) . Group DataFrame by column . df.groupby(&#39;column&#39;) . Sort values of column . df.sortvalues(&#39;column to use&#39;, ascending=True) . Filter DataFrame by multiple OR conditions . df[df.column.isin([&#39;value 1&#39;, &#39;value2&#39;, &#39;value3&#39;])] . Invert filter . df[~df.column.isin([&#39;value 1&#39;, &#39;value2&#39;, &#39;value3&#39;])] . Rename columns . df.rename(columns = {&#39;current name&#39;:&#39;target name&#39;}) . Add prefix to column name . df.add_prefix(&#39;prefix&#39;) . Add suffix to column name . df.add_suffix(&#39;suffix&#39;) . Gather columns into rows . pd.melt(df) . Spread rows into columns . df.pivot(columns=&#39;columns to use&#39;,values=&#39;values to use&#39;) . Select rows by position . df.iloc[0:9] . Select and order top n entries . df.nlargest(n) . Select and order bottom n entries . df.nsmallest(n) . Select columns whose name matches regular expression . df.filter(regex=&#39;search term&#39;) . Make column of strings uppercase . df[&#39;column&#39;].str.upper() . Append rows of multiple dataframes . df.concat([df1, df2]) . Append columns of multiple dataframes . df.concat([df1, df2], axis=1) . Join matching rows drom df1 to df . pd.merge(df1,df2, how=&#39;left&#39;, on=&#39;column to join on&#39;) . Join rows from df2 to df1 . pd.merge(df1,df2, how=&#39;right&#39;, on=&#39;column to join on&#39;) . Join data, retain only rows in both sets . pd.merge(df1,df2, how=&#39;inner&#39;, on=&#39;column to join on&#39;) . Join data, retain all values, all rows . pd.merge(df1,df2, how=&#39;outer&#39;, on=&#39;column to join on&#39;) . Split dataframe into two random subsets, only works if index is unique . df1 = df.sample(frac=0.5,random_state=42); df2 = df.drop(df1.index) . Apply function to dataframe . f = lambda x: &lt;function&gt;; df.apply(f) . df.insert(&lt;location, e.g. 3&gt;, &#39;column name&#39;) . Split string to new column, keeping first word . df[&#39;column&#39;] = df.column.str.split(&#39;, &#39;,expand=True)[0] . Descriptive Statistics . df.describe().round(3) . Sum values of each object. . df.sum() . Median value of each object. . df.median() . Quantiles of each object. . df.quantile([0.25,0.75]) . Minimum value in each object . df.min() . Maximum value in each object. . df.max() . Mean value of each object. . df.mean() . Variance of each object. . df.var() . Standard deviation of each object . df.std() . Count non-NA/null values of each object. . df.count() . Feature Engineering . One hot encode columns . pd.get_dummies(df) . Interpolate missing values in time series data . df.interpolate() . Fill null values . df[&#39;column to find null values&#39;].fillna(value=df[&#39;column with null values&#39;].median(),¬†inplace=True) . Data Visulations . Column distributions . df_nona = df.dropna(axis=0, how=&#39;any&#39;, subset=[&#39;list of columns to subset&#39;]) ax_list¬†=¬†df.hist(bins=25,¬†layout=(4,4),¬†figsize=(15,15)) df_nona.describe().round(3) . Corrleation heatmap . CATEGORICAL_FEATURES = [&#39;list of columns with categorical features&#39;] corr = df[CATEGORICAL_FEATURES].corr() mask¬†=¬†np.triu(np.ones_like(corr,¬†dtype=np.bool)) plt.figure(figsize=(20,10)) cmap¬†=¬†sns.diverging_palette(230,¬†20,¬†as_cmap=True) sns.heatmap(corr,mask=mask,cmap=cmap,annot=True) . Calendar heatmap . flights = sns.load_dataset(&quot;flights&quot;) flights = flights.pivot(&quot;month&quot;, &quot;year&quot;, &quot;passengers&quot;) sns.heatmap(flights, annot=True, fmt=&quot;d&quot;) plt.show() . Save figure . plt.savefig(&#39;filename.ext&#39;) .",
            "url": "https://andrewryanx.github.io/site/python/2021/01/29/py-cheatsheet.html",
            "relUrl": "/python/2021/01/29/py-cheatsheet.html",
            "date": " ‚Ä¢ Jan 29, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://andrewryanx.github.io/site/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Landing page for projects and ideas . üî≠ I‚Äôm currently working on ‚Ä¶ | üå± I‚Äôm currently learning ‚Ä¶ | üëØ I‚Äôm looking to collaborate on ‚Ä¶ | ü§î I‚Äôm looking for help with ‚Ä¶ | üí¨ Ask me about ‚Ä¶ | üì´ How to reach me: ‚Ä¶ | üòÑ Pronouns: ‚Ä¶ | ‚ö° Fun fact: ‚Ä¶ . | .",
          "url": "https://andrewryanx.github.io/site/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
      ,"page3": {
          "title": "Projects",
          "content": ". Projects &amp; Tutorials . . Web Maps . Tweet Map . DC Potholes . .",
          "url": "https://andrewryanx.github.io/site/projects/",
          "relUrl": "/projects/",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "Resources",
          "content": ". Cheat Sheets . I‚Äôm beginning to put together cheat sheets for quick access to important/useful data science information! . I‚Äôll be working on adding more to this list and proving examples. . If you see something that is incorrect or would like to add to it, feel free to reach out. . Data Science Glossary . Python Cheat Sheet . Statistics Cheat Sheet . Machine Learning Cheat Sheet . Ubuntu Cheat Sheet . . Other Resources . Data Scientist Path - Microsoft Learn . Foundations of Data Science - Microsoft Learn . Elements of Data Science - AWS Training . Math for Machine Learning - AWS Training . YouTube Playlists: . Machine Learning - Andrew Ng . Stanford CS229: Machine Learning, Autumn 2018 - Andrew Ng . Neural Networks and Deep Learning (Course 1 of the Deep Learning Specialization) - Andrew Ng . Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization (Course 2 of the Deep Learning Specialization) - Andrew Ng . Structuring Machine Learning Projects (Course 3 of the Deep Learning Specialization) - Andrew Ng . Convolutional Neural Networks (Course 4 of the Deep Learning Specialization) - Andrew Ng . Stanford CS221: Artificial Intelligence: Principles and Techniques, Autumn 2019 . MIT 18.650 Statistics for Applications, Fall 2016 . Computer Vision: Amazon Machine Learning University (MLU) . .",
          "url": "https://andrewryanx.github.io/site/resources/",
          "relUrl": "/resources/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "Resume",
          "content": "Professional Experience . Staff Data Scientist, Maxar Technologies - Herndon, VA . January 2019 - Present . | . Geospatial Analyst/Cartographer, ActioNet, Inc. - Washington, D.C . September 2018 - January 2019 . | . Geospatial Data Scientist, Maxar Technologies - Washington, D.C. / Reston, VA . June 2016 - September 2018 . | . Intern, U.S. Department of State - Washington, D.C . March 2016 - June 2016 . | . Geospatial Analyst, Virginia Tech - Blacksburg, VA . March 2014 - June 2016 . | . . Projects . See Projects . . Skills . Programming Languages: Python, SQL . Data Science: Python, machine learning, deep learning, exploratory data analysis, descriptive statistics, data cleaning, feature engineering, data visualization, NVIDIA DIGITS, Jupyter Notebooks . Domain Expertise: Geospatial analytics, All-Source intelligence, Pattern of Life analytics, social network analysis . Misc: Ubuntu/Linux, CLI, PyCharm, VSCode, AWS EC2, AWS S3, GitHub, Jira, Confluence, Markdown, ArcGIS, QGIS . . Education . PhD., Earth Systems &amp; Geoinformation Science, George Mason University . August 2019 - Present . Relevant coursework: Deep Learning for Geoinformatics | . M.S, Geospatial Intelligence, George Mason University . August 2016 - May 2019 . Relevant coursework: Scientific Data Mining for Geoinformatics, Spatial Data Structures, GIS Algorithms, GIS Algorithms and Programming, Quantitative Methods | . B.A., Geography, Virginia Tech . August 2011 - May 2015 . . Certificates, Awards, &amp; Organizations . Elements of Data Science - AWS | Master Python for Data Science - LinkedIn Learning | Python for Data Science Essential Training 1 - LinkedIn Learning | Python for Data Science Essential Training 2 - LinkedIn Learning | Mastering Python for Data Science - LinkedIn Learning | Applied Machine Learning: Foundations - LinkedIn Learning | Applied Machine Learning: Feature Engineering - LinkedIn Learning | Applied Machine Learning: Algorithms - LinkedIn Learning | . . United States Geospatial Intelligence Foundation (USGIF) Scholarship, 2016-2017 | United States Geospatial Intelligence Foundation (USGIF) Scholarship, 2017 - 2018 | United States Geospatial Intelligence Foundation (USGIF) Scholarship, 2018 - 2019 | Certificate of Appreciation, U.S. Department of State, 2018 | Certificate of Appreciation, U.S. Department of State, 2016 | . . USGIF Machine Learning &amp; Artificial Intelligence Working Group | USGIF Young Professionals Group (YPG) | American Association of Geographers (AAG) | American Geographical Society (AGS) | Geo DC | .",
          "url": "https://andrewryanx.github.io/site/resume/",
          "relUrl": "/resume/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://andrewryanx.github.io/site/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}